{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f32ff1",
   "metadata": {},
   "source": [
    "# Lesson 2: Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb345ad0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bbf530-3f05-434c-a70f-ac2cc4b8f7aa",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c06c95-e8b2-4574-b14d-685876aa1c47",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53c064",
   "metadata": {},
   "source": [
    "## 1. Define a Simple Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071b717a-93cc-4332-b357-59a693359563",
   "metadata": {
    "height": 234,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e62118-992b-4629-9022-be8c628209c1",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"Tell me the output of the mystery function on 2 and 9\", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8a835",
   "metadata": {},
   "source": [
    "## 2. Define an Auto-Retrieval Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589123f",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdea238",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe9326c-d7b3-452b-ae52-12f000157be4",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"JM3 3.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5451f0a3-d0a6-4b5c-a337-8e1a343ff5f0",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fe0a9c-1f87-4ae7-a79e-7c3cf9c395ed",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: JM3 3.pdf\n",
      "file_path: JM3 3.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 244011\n",
      "creation_date: 2024-07-18\n",
      "last_modified_date: 2024-07-18\n",
      "\n",
      "Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ©2023. All\n",
      "rights reserved. Draft of February 3, 2024.\n",
      "CHAPTER\n",
      "3N-gram Language Models\n",
      "“You are uniformly charming!” cried he, with a smile of associating and now\n",
      "and then I bowed and they perceived a chaise and four to wish for.\n",
      "Random sentence generated from a Jane Austen trigram model\n",
      "Predicting is difﬁcult—especially about the future, as the old quip goes. But how\n",
      "about predicting something that seems much easier, like the next few words someone\n",
      "is going to say? What word, for example, is likely to follow\n",
      "Please turn your homework ...\n",
      "Hopefully, most of you concluded that a very likely word is in, or possibly over,\n",
      "but probably not refrigerator orthe. In this chapter we formalize this intuition by\n",
      "introducing models that assign a probability to each possible next word.\n",
      "Models that assign probabilities to upcoming words, or sequences of words\n",
      "in general, are called language models orLMs . Why would we want to predict language model\n",
      "LM upcoming words? It turns out that the large language models that revolutionized\n",
      "modern NLP are trained just by predicting words!! As we’ll see in chapters 7-10,\n",
      "large language models learn an enormous amount about language solely from being\n",
      "trained to predict upcoming words from neighboring words.\n",
      "Language models can also assign a probability to an entire sentence. For exam-\n",
      "ple, they can predict that the following sequence has a much higher probability of\n",
      "appearing in a text:\n",
      "all of a sudden I notice three guys standing on the sidewalk\n",
      "than does this same set of words in a different order:\n",
      "on guys all I of notice sidewalk three a sudden standing the\n",
      "Why does it matter what the probability of a sentence is or how probable the\n",
      "next word is? In many NLP applications we can use the probability as a way to\n",
      "choose a better sentence or word over a less-appropriate one. For example we can\n",
      "correct grammar or spelling errors like Their are two midterms , in which There was\n",
      "mistyped as Their , orEverything has improve , in which improve should have been\n",
      "improved . The phrase There are will be much more probable than Their are , and has\n",
      "improved than has improve , allowing a language model to help users select the more\n",
      "grammatical variant. Or for a speech recognizer to realize that you said I will be back\n",
      "soonish and not I will be bassoon dish , it helps to know that back soonish is a much\n",
      "more probable sequence. Language models can also help in augmentative and\n",
      "alternative communication systems (Trnka et al. 2007, Kane et al. 2017). People\n",
      "often use such AAC devices if they are physically unable to speak or sign but can AAC\n",
      "instead use eye gaze or other speciﬁc movements to select words from a menu. Word\n",
      "prediction can be used to suggest likely words for the menu.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7965cba-67b8-4cca-8e5f-2b0dbc96f6b0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "560f319c-8479-40c5-9b55-480fef98deb7",
   "metadata": {
    "height": 251,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are N-Grams\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2da4042f-8fdb-4959-8760-86685c903cfd",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Grams are sequences of n words, where n can be any number. For example, a 2-gram (bigram) is a sequence of two words, like \"please turn\", while a 3-gram (trigram) is a sequence of three words, such as \"please turn your\". N-Grams are also used to refer to probabilistic models that estimate the probability of a word given the n-1 previous words, allowing for the calculation of probabilities for entire sequences of words.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30bb264c-42e0-46f8-9d28-da11a8535960",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c392482",
   "metadata": {},
   "source": [
    "### Define the Auto-Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2639e79b-f615-425b-85ea-8a279bb26dd0",
   "metadata": {
    "height": 608,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    page_numbers: List[str]\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [\n",
    "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "    \n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a408ace-cf25-425b-8248-7028ceabcd42",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"N-Grams\", \"page_numbers\": [\"2\"]}\n",
      "=== Function Output ===\n",
      "N-grams are sequences of n words, such as bigrams (2-word sequences) and trigrams (3-word sequences). They are used to build language models that estimate the probability of a word given the n-1 previous words. N-grams play a fundamental role in language modeling, helping with tasks like computing probabilities of word sequences, training and testing sets, calculating perplexity, sampling, and interpolation. While n-grams provide a simple formalization for language modeling, more advanced models like neural large language models based on transformer architectures are also used for more complex tasks.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"What is N-Grams as described on page 2?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4633093",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"N-Grams\", \"page_numbers\": [\"3\"]}\n",
      "=== Function Output ===\n",
      "N-Grams are a type of probabilistic language model used in natural language processing. They are based on the idea that the probability of a word in a sequence can be approximated by considering the probability of that word given the previous n-1 words. In the context provided, the bigram model is specifically mentioned, where the probability of a word is approximated by considering only the preceding word. This approach simplifies the computation of probabilities for sequences of words by making the Markov assumption that the probability of a word depends only on the immediately preceding word.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"What is N-Grams as described on page 3?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f712bb1",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"equations\", \"page_numbers\": [\"3\"]}\n",
      "=== Function Output ===\n",
      "Equations 3.3, 3.4, 3.5, 3.6, and 3.7 are discussed in the provided text.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"Print the equations on page 3 in latex\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ec05565-6adf-4294-ba5c-b384220876ac",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '3', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef4dec0",
   "metadata": {},
   "source": [
    "## Let's add some other tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55dd32e5-e29f-42ed-839a-ca937fe4743e",
   "metadata": {
    "height": 268,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4228ca7c-42a0-494b-987b-5a1c5c584536",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"Perplexity\", \"page_numbers\": [\"8\"]}\n",
      "=== Function Output ===\n",
      "Perplexity is a metric used to evaluate language models in natural language processing. It is calculated as the inverse probability of a test set, normalized by the number of words in the set. Essentially, perplexity measures how well a language model predicts a given test set, with lower perplexity values indicating better performance.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"Get Perplexity on page 8 and summarize it\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b04a7079",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21906d47-7266-4479-bbb4-9f392d5c399b",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"Summarize\"}\n",
      "=== Function Output ===\n",
      "N-gram language models are discussed, focusing on predicting word probabilities based on previous words. The models simplify predictions by assuming word probabilities depend on the previous n-1 words. Bigram probabilities are calculated using maximum likelihood estimation. Perplexity is used to evaluate model performance, with lower values indicating better models. Techniques like smoothing and handling unknown words are introduced to address challenges in language models. Vocabulary management, backoff, interpolation, and setting λ values are also discussed in the context of language modeling. The history of n-gram models, advancements in smoothing techniques, and the shift towards neural network models are highlighted. Various approaches to language modeling, including n-grams and neural networks, have been explored over the years to improve word prediction and communication rate in AAC systems.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"Summarize\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3f3e22c",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '2', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '3', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '4', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '5', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '6', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '7', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '8', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '9', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '10', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '11', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '12', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '13', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '14', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '15', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '16', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '16', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '17', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '18', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '19', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '20', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '21', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '22', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '23', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '24', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '25', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '26', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '27', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '28', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '29', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '29', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '30', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f04d55ed",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"Perplexity is a measurement used in natural language processing to evaluate the performance of language models. It indicates how well a probability distribution or language model predicts a sample. A lower perplexity score indicates better performance, as it signifies that the model is more certain about its predictions. Perplexity is calculated as the inverse probability of the test set, normalized by the number of words.\"}\n",
      "=== Function Output ===\n",
      "Perplexity is a metric commonly used in natural language processing to evaluate the performance of language models. It provides insight into how accurately a probability distribution or language model can predict a given sample. A lower perplexity score is preferred as it indicates better performance, suggesting that the model is more confident in its predictions. The calculation of perplexity involves taking the inverse probability of the test set and normalizing it by the number of words in the set.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"Summarize Perplexity\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67f3d2cd",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '2', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '3', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '4', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '5', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '6', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '7', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '8', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '9', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '10', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '11', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '12', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '13', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '14', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '15', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '16', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '16', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '17', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '18', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '19', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '20', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '21', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '22', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '23', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '24', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '25', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '26', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '27', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '28', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '29', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '29', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n",
      "{'page_label': '30', 'file_name': 'JM3 3.pdf', 'file_path': 'JM3 3.pdf', 'file_type': 'application/pdf', 'file_size': 244011, 'creation_date': '2024-07-18', 'last_modified_date': '2024-07-18'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
